{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os, sys\n",
    "from six.moves import urllib\n",
    "import tarfile\n",
    "import zipfile\n",
    "from skimage import io, color\n",
    "import scipy.io\n",
    "\n",
    "\n",
    "def maybe_download_and_extract(dir_path, url_name, is_tarfile=True, is_zipfile=False):\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "    filename = url_name.split('/')[-1]\n",
    "    filepath = os.path.join(dir_path, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "        def _progress(count, block_size, total_size):\n",
    "            sys.stdout.write(\n",
    "                '\\r>> Downloading DATASET %s %.1f%%' % (filename, float(count * block_size) / float(total_size) * 100.0))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        #filepath, _ = urllib.request.urlretrieve(url_name, filepath, reporthook=_progress)\n",
    "        filepath='/home/shikhar/Desktop/full run/abc.tar'\n",
    "        print(\"in maybe_download_and_extract\")\n",
    "        statinfo = os.stat(filepath)\n",
    "        print('Succesfully downloaded', filename, statinfo.st_size, 'bytes.')\n",
    "        if is_tarfile:\n",
    "            tarfile.open(filepath, 'r:').extractall(dir_path)\n",
    "        elif is_zipfile:\n",
    "            with zipfile.ZipFile(filepath) as zf:\n",
    "                zip_dir = zf.namelist()[0]\n",
    "                zf.extractall(dir_path)\n",
    "\n",
    "\n",
    "def get_model_data(dir_path, model_url):\n",
    "    maybe_download_and_extract(dir_path, model_url)\n",
    "    filename = model_url.split(\"/\")[-1]\n",
    "    filepath = os.path.join(dir_path, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "        raise IOError(\"VGG Model not found!\")\n",
    "    data = scipy.io.loadmat('/home/shikhar/Desktop/full run/imagenet-vgg-verydeep-19.mat')\n",
    "    return data\n",
    "\n",
    "\n",
    "def save_image(image, save_dir, name):\n",
    "    \"\"\"\n",
    "    Save image by unprocessing and converting to rgb.\n",
    "    :param image: iamge to save\n",
    "    :param save_dir: location to save image at\n",
    "    :param name: prefix to save filename\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    image = color.lab2rgb(image)\n",
    "    io.imsave(os.path.join(save_dir, name + \".png\"), image)\n",
    "\n",
    "\n",
    "def get_variable(weights, name):\n",
    "    init = tf.constant_initializer(weights, dtype=tf.float32)\n",
    "    var = tf.get_variable(name=name, initializer=init, shape=weights.shape)\n",
    "    return var\n",
    "\n",
    "\n",
    "def weight_variable(shape, stddev=0.02, name=None):\n",
    "    initial = tf.truncated_normal(shape, stddev=stddev)\n",
    "    if name is None:\n",
    "        return tf.Variable(initial)\n",
    "    else:\n",
    "        return tf.get_variable(name, initializer=initial)\n",
    "\n",
    "\n",
    "def bias_variable(shape, name=None):\n",
    "    initial = tf.constant(0.0, shape=shape)\n",
    "    if name is None:\n",
    "        return tf.Variable(initial)\n",
    "    else:\n",
    "        return tf.get_variable(name, initializer=initial)\n",
    "\n",
    "\n",
    "def get_tensor_size(tensor):\n",
    "    from operator import mul\n",
    "    return reduce(mul, (d.value for d in tensor.get_shape()), 1)\n",
    "\n",
    "\n",
    "def conv2d_basic(x, W, bias):\n",
    "    conv = tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "    return tf.nn.bias_add(conv, bias)\n",
    "\n",
    "\n",
    "def conv2d_strided(x, W, b):\n",
    "    conv = tf.nn.conv2d(x, W, strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "    return tf.nn.bias_add(conv, b)\n",
    "\n",
    "\n",
    "def conv2d_transpose_strided(x, W, b, output_shape=None, stride=2):\n",
    "    # print x.get_shape()\n",
    "    # print W.get_shape()\n",
    "    if output_shape is None:\n",
    "        output_shape = x.get_shape().as_list()\n",
    "        output_shape[1] *= 2\n",
    "        output_shape[2] *= 2\n",
    "        output_shape[3] = W.get_shape().as_list()[2]\n",
    "    # print output_shape\n",
    "    conv = tf.nn.conv2d_transpose(x, W, output_shape, strides=[1, stride, stride, 1], padding=\"SAME\")\n",
    "    return tf.nn.bias_add(conv, b)\n",
    "\n",
    "\n",
    "def leaky_relu(x, alpha=0.2, name=\"\"):\n",
    "    return tf.maximum(alpha * x, x, name)\n",
    "\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "\n",
    "def avg_pool_2x2(x):\n",
    "    return tf.nn.avg_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "\n",
    "def batch_norm(x, n_out, phase_train, scope='bn', decay=0.9, eps=1e-5, stddev=0.02):\n",
    "    \"\"\"\n",
    "    Code taken from http://stackoverflow.com/a/34634291/2267819\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(scope):\n",
    "        beta = tf.get_variable(name='beta', shape=[n_out], initializer=tf.constant_initializer(0.0)\n",
    "                               , trainable=True)\n",
    "        gamma = tf.get_variable(name='gamma', shape=[n_out], initializer=tf.random_normal_initializer(1.0, stddev),\n",
    "                                trainable=True)\n",
    "        batch_mean, batch_var = tf.nn.moments(x, [0, 1, 2], name='moments')\n",
    "        ema = tf.train.ExponentialMovingAverage(decay=decay)\n",
    "\n",
    "        def mean_var_with_update():\n",
    "            ema_apply_op = ema.apply([batch_mean, batch_var])\n",
    "            with tf.control_dependencies([ema_apply_op]):\n",
    "                return tf.identity(batch_mean), tf.identity(batch_var)\n",
    "\n",
    "        mean, var = tf.cond(phase_train,\n",
    "                            mean_var_with_update,\n",
    "                            lambda: (ema.average(batch_mean), ema.average(batch_var)))\n",
    "        normed = tf.nn.batch_normalization(x, mean, var, beta, gamma, eps)\n",
    "    return normed\n",
    "\n",
    "\n",
    "def process_image(image, mean_pixel):\n",
    "    return image - mean_pixel\n",
    "\n",
    "\n",
    "def unprocess_image(image, mean_pixel):\n",
    "    return image + mean_pixel\n",
    "\n",
    "\n",
    "def add_to_regularization_and_summary(var):\n",
    "    if var is not None:\n",
    "        tf.summary.histogram(var.op.name, var)\n",
    "        tf.add_to_collection(\"reg_loss\", tf.nn.l2_loss(var))\n",
    "\n",
    "\n",
    "def add_activation_summary(var):\n",
    "    tf.summary.histogram(var.op.name + \"/activation\", var)\n",
    "    tf.scalar_summary(var.op.name + \"/sparsity\", tf.nn.zero_fraction(var))\n",
    "\n",
    "\n",
    "def add_gradient_summary(grad, var):\n",
    "    if grad is not None:\n",
    "        tf.summary.histogram(var.op.name + \"/gradient\", grad)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "The residual code below is taken and modified\n",
    " from https://github.com/tensorflow/models/blob/master/resnet/resnet_model.py\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def residual_block(x, in_filter, out_filter, stride, phase_train, is_conv=True, leakiness=0.0,\n",
    "                   activate_before_residual=False):\n",
    "    \"\"\"Residual unit with 2 sub layers.\"\"\"\n",
    "    if activate_before_residual:\n",
    "        with tf.variable_scope('shared_activation'):\n",
    "            x = batch_norm(x, out_filter, phase_train, scope=\"init_bn\")\n",
    "            x = leaky_relu(x, alpha=leakiness, name=\"lrelu\")\n",
    "            orig_x = x\n",
    "    else:\n",
    "        with tf.variable_scope('residual_only_activation'):\n",
    "            orig_x = x\n",
    "            x = batch_norm(x, out_filter, phase_train, scope=\"init_bn\")\n",
    "            x = leaky_relu(x, alpha=leakiness, name=\"lrelu\")\n",
    "\n",
    "    with tf.variable_scope('sub1'):\n",
    "        if is_conv:\n",
    "            x = conv_no_bias('conv1', x, 3, in_filter, out_filter, stride)\n",
    "        else:\n",
    "            x = conv_transpose_no_bias('conv_t1', x, 3, in_filter, out_filter, stride)\n",
    "\n",
    "    with tf.variable_scope('sub2'):\n",
    "        x = batch_norm(x, out_filter, phase_train, scope=\"bn2\")\n",
    "        x = tf.nn.relu(x, \"relu\")\n",
    "        if is_conv:\n",
    "            x = conv_no_bias('conv2', x, 3, out_filter, out_filter, [1, 1, 1, 1])\n",
    "        else:\n",
    "            x = conv_transpose_no_bias('conv_t2', x, 3, in_filter, in_filter, [1, 1, 1, 1])\n",
    "\n",
    "    with tf.variable_scope('sub_add'):\n",
    "        if in_filter != out_filter:\n",
    "            if is_conv:\n",
    "                orig_x = tf.nn.avg_pool(orig_x, stride, stride, 'VALID')\n",
    "            else:\n",
    "                orig_x = tf.nn.fractional_avg_pool(orig_x, stride)  # Available only in tf 0.11 - not tested\n",
    "            orig_x = tf.pad(\n",
    "                orig_x, [[0, 0], [0, 0], [0, 0],\n",
    "                         [(out_filter - in_filter) // 2, (out_filter - in_filter) // 2]])\n",
    "        x += orig_x\n",
    "\n",
    "    # tf.logging.info('image after unit %s', x.get_shape())\n",
    "    return x\n",
    "\n",
    "\n",
    "def bottleneck_residual_block(x, in_filter, out_filter, stride, phase_train, is_conv=True, leakiness=0.0,\n",
    "                              activate_before_residual=False):\n",
    "    \"\"\"Bottleneck resisual unit with 3 sub layers.\"\"\"\n",
    "    if activate_before_residual:\n",
    "        with tf.variable_scope('common_bn_relu'):\n",
    "            x = batch_norm(x, out_filter, phase_train, scope=\"init_bn\")\n",
    "            x = leaky_relu(x, alpha=leakiness, name=\"lrelu\")\n",
    "            orig_x = x\n",
    "    else:\n",
    "        with tf.variable_scope('residual_bn_relu'):\n",
    "            orig_x = x\n",
    "            x = batch_norm(x, out_filter, phase_train, scope=\"init_bn\")\n",
    "            x = leaky_relu(x, alpha=leakiness, name=\"lrelu\")\n",
    "\n",
    "    with tf.variable_scope('sub1'):\n",
    "        if is_conv:\n",
    "            x = conv_no_bias('conv1', x, 1, in_filter, out_filter / 4, stride)\n",
    "        else:\n",
    "            x = conv_transpose_no_bias('conv_t1', x, 1, out_filter / 4, out_filter, stride)\n",
    "\n",
    "    with tf.variable_scope('sub2'):\n",
    "        x = batch_norm(x, out_filter, phase_train, scope=\"bn2\")\n",
    "        x = leaky_relu(x, alpha=leakiness, name=\"lrelu\")\n",
    "        if is_conv:\n",
    "            x = conv_no_bias('conv2', x, 3, out_filter / 4, out_filter / 4, [1, 1, 1, 1])\n",
    "        else:\n",
    "            x = conv_transpose_no_bias('conv_t2', x, 3, out_filter / 4, out_filter / 4, [1, 1, 1, 1])\n",
    "\n",
    "    with tf.variable_scope('sub3'):\n",
    "        x = batch_norm(x, out_filter, phase_train, scope=\"bn3\")\n",
    "        x = leaky_relu(x, alpha=leakiness, name=\"lrelu\")\n",
    "        if is_conv:\n",
    "            x = conv_no_bias('conv3', x, 1, out_filter / 4, out_filter, [1, 1, 1, 1])\n",
    "        else:\n",
    "            x = conv_transpose_no_bias('conv_t3', x, 1, in_filter, out_filter / 4, [1, 1, 1, 1])\n",
    "\n",
    "    with tf.variable_scope('sub_add'):\n",
    "        if in_filter != out_filter:\n",
    "            if is_conv:\n",
    "                orig_x = conv_no_bias('project', orig_x, 1, in_filter, out_filter, stride)\n",
    "            else:\n",
    "                orig_x = conv_transpose_no_bias('project', orig_x, 1, in_filter, out_filter, stride)\n",
    "        x += orig_x\n",
    "\n",
    "    # tf.logging.info('image after unit %s', x.get_shape())\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_no_bias(name, x, filter_size, in_filters, out_filters, strides):\n",
    "    \"\"\"Convolution.\"\"\"\n",
    "    with tf.variable_scope(name):\n",
    "        n = filter_size * filter_size * out_filters\n",
    "        kernel = tf.get_variable(\n",
    "            'DW', [filter_size, filter_size, in_filters, out_filters],\n",
    "            tf.float32, initializer=tf.random_normal_initializer(\n",
    "                stddev=np.sqrt(2.0 / n)))\n",
    "        return tf.nn.conv2d(x, kernel, strides, padding='SAME')\n",
    "\n",
    "\n",
    "def conv_transpose_no_bias(name, x, filter_size, in_filters, out_filters, strides):\n",
    "    \"\"\"Convolution Transpose.\"\"\"\n",
    "    with tf.variable_scope(name):\n",
    "        n = filter_size * filter_size * out_filters\n",
    "        kernel = tf.get_variable(\n",
    "            'DW', [filter_size, filter_size, in_filters, out_filters],\n",
    "            tf.float32, initializer=tf.random_normal_initializer(\n",
    "                stddev=np.sqrt(2.0 / n)))\n",
    "\n",
    "        output_shape = tf.shape(x)\n",
    "        output_shape[1] *= strides[1]\n",
    "        output_shape[2] *= strides[2]\n",
    "        output_shape[3] = in_filters\n",
    "\n",
    "        return tf.nn.conv2d_transpose(x, kernel, output_shape=output_shape, strides=strides, padding='SAME')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
